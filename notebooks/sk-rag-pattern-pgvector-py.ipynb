{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "\n",
    "#from psycopg import Cursor\n",
    "#from psycopg.sql import SQL, Identifier\n",
    "#from psycopg_pool import ConnectionPool\n",
    "from semantic_kernel.connectors.memory.postgres.postgres_memory_store import (\n",
    "    PostgresMemoryStore,\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "endpoint = os.getenv(\"GPT_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"GPT_OPENAI_KEY\")\n",
    "gpt_deployment_name = os.getenv(\"GPT_OPENAI_DEPLOYMENT_NAME\")\n",
    "conn_str = os.getenv(\"PG_CONN_STR_PY\")\n",
    "ada_deployment_name = \"ada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='text_memory', description=None, functions={'recall': KernelFunction(plugin_name='text_memory', description='Recall a fact from the long term memory', name='recall', is_semantic=False, stream_function=<bound method TextMemoryPlugin.recall of TextMemoryPlugin()>, parameters=[ParameterView(name='input', description='The information to retrieve', default_value='', type_='string', required=False), ParameterView(name='limit', description='The maximum number of relevant memories to recall.', default_value='1', type_='string', required=False), ParameterView(name='relevance', description='The relevance score, from 0.0 to 1.0; 1.0 means perfect match', default_value='0.75', type_='string', required=False), ParameterView(name='collection', description='The collection to search for information', default_value='generic', type_='string', required=False)], delegate_type=<DelegateTypes.InStringAndContextOutTaskString: 13>, function=<bound method TextMemoryPlugin.recall of TextMemoryPlugin()>, plugins=KernelPluginCollection(plugins={'text_memory': KernelPlugin(name='text_memory', description=None, functions={...})}), ai_service=None, prompt_execution_settings=PromptExecutionSettings(service_id=None, extension_data={}), chat_prompt_template=None), 'save': KernelFunction(plugin_name='text_memory', description='Save information to semantic memory', name='save', is_semantic=False, stream_function=<bound method TextMemoryPlugin.save of TextMemoryPlugin()>, parameters=[ParameterView(name='input', description='The information to save', default_value='', type_='string', required=False), ParameterView(name='key', description='The unique key to associate with the information', default_value='', type_='string', required=False), ParameterView(name='collection', description='The collection to save the information', default_value='generic', type_='string', required=False)], delegate_type=<DelegateTypes.InStringAndContextOutTask: 17>, function=<bound method TextMemoryPlugin.save of TextMemoryPlugin()>, plugins=KernelPluginCollection(plugins={'text_memory': KernelPlugin(name='text_memory', description=None, functions={...})}), ai_service=None, prompt_execution_settings=PromptExecutionSettings(service_id=None, extension_data={}), chat_prompt_template=None)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "azure_chat_service = AzureChatCompletion(deployment_name=gpt_deployment_name, endpoint=endpoint, api_key=api_key)\n",
    "azure_text_embedding = AzureTextEmbedding(deployment_name=ada_deployment_name, endpoint=endpoint, api_key=api_key)\n",
    "kernel.add_chat_service(\"chat_completion\", azure_chat_service)\n",
    "kernel.add_text_embedding_generation_service(\"ada\", azure_text_embedding)\n",
    "\n",
    "mem_store = PostgresMemoryStore(conn_str,1536,1,3)\n",
    "kernel.register_memory_store(memory_store=mem_store)\n",
    "kernel.import_plugin(sk.core_plugins.TextMemoryPlugin(), \"text_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def populate_memory(kernel: sk.Kernel) -> None:\n",
    "    # Add some documents to the semantic memory\n",
    "    await kernel.memory.save_information(collection=\"aboutMe\", id=\"info1\", text=\"My name is Andrea\")\n",
    "    await kernel.memory.save_information(collection=\"aboutMe\", id=\"info2\", text=\"I currently work as a tour guide\")\n",
    "    await kernel.memory.save_information(\n",
    "        collection=\"aboutMe\", id=\"info3\", text=\"I've been living in Seattle since 2005\"\n",
    "    )\n",
    "    await kernel.memory.save_information(\n",
    "        collection=\"aboutMe\",\n",
    "        id=\"info4\",\n",
    "        text=\"I visited France and Italy five times since 2015\",\n",
    "    )\n",
    "    await kernel.memory.save_information(collection=\"aboutMe\", id=\"info5\", text=\"My family is from New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "await populate_memory(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_memory_examples(kernel: sk.Kernel) -> None:\n",
    "    questions = [\n",
    "        \"what's my name\",\n",
    "        \"where do I live?\",\n",
    "        \"where's my family from?\",\n",
    "        \"where have I traveled?\",\n",
    "        \"what do I do for work\",\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        print(f\"Question: {question}\")\n",
    "        result = await kernel.memory.search(\"aboutMe\", question)\n",
    "        print(f\"Answer: {result[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what's my name\n",
      "Answer: My name is Andrea\n",
      "\n",
      "Question: where do I live?\n",
      "Answer: I've been living in Seattle since 2005\n",
      "\n",
      "Question: where's my family from?\n",
      "Answer: My family is from New York\n",
      "\n",
      "Question: where have I traveled?\n",
      "Answer: I visited France and Italy five times since 2015\n",
      "\n",
      "Question: what do I do for work\n",
      "Answer: I currently work as a tour guide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await search_memory_examples(kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v31012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
