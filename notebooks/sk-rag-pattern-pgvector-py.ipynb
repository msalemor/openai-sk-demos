{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python RAG Pattern with Semantic Kernel and PgVector\n",
    "\n",
    "## Azure PostgreSQL Flexible Server - PGVector Setup in Azure\n",
    "\n",
    "Running locally with a container:\n",
    "\n",
    "- docker pull pgvector/pgvector:pg16\n",
    "- Then execute:\n",
    "\n",
    "```bash\n",
    "docker run --name pgvector16 \\\n",
    "  --restart unless-stopped \\\n",
    "  -p 5432:5432 \\\n",
    "  -v pgdata:/var/lib/postgresql/data \\\n",
    "  -d pgvector/pgvector:pg16\n",
    "```\n",
    "- After deployment, connect using psql and type: `CREATE EXTENSION vector;`\n",
    "\n",
    "Manual Instructions:\n",
    "\n",
    "- Create a Flexible server instance in the Azure Portal\n",
    "- After creation, navigate to the Server Parameters pane:\n",
    "  - Search for azure.extensions\n",
    "  - Check the `Vector` value\n",
    "  - Save the changes and wait for the server to deploy\n",
    "- After deployment, open the instance and navigate to the `Database` panel:\n",
    "  - Click `Connect` link on the Postgres database\n",
    "    - Using the Cloud Shell psql, active the vector extension by typing: `CREATE EXTENSION vector;`\n",
    "\n",
    "Connection string:\n",
    "- `PG_CONN_STR_PY=\"postgresql://<user>:<password>@<server>:5432/<database>\"`\n",
    "\n",
    "Useful commands:\n",
    "\n",
    "- `truncate table public.\"PYCollection\";`\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "from semantic_kernel.connectors.memory.postgres.postgres_memory_store import (\n",
    "    PostgresMemoryStore,\n",
    ")\n",
    "import psycopg as cursor\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "COLLECTION_NAME = \"PYCollection\"\n",
    "ADA_EMBEDDINGS_SIZE = 1536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "endpoint = os.getenv(\"GPT_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"GPT_OPENAI_KEY\")\n",
    "gpt_deployment_name = os.getenv(\"GPT_OPENAI_DEPLOYMENT_NAME\")\n",
    "conn_str = os.getenv(\"PG_CONN_STR_PY\")\n",
    "ada_deployment_name = \"ada\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear the PgVector embeddings table on every run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = cursor.connect(conn_str)\n",
    "    conn.execute(f'truncate table \"{COLLECTION_NAME}\"')\n",
    "    print(f\"{COLLECTION_NAME} table truncated\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "except:\n",
    "    print(\"Unable to truncate the table. It may not exist yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a kernel instance configured for text completions and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is ready to use\n"
     ]
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "azure_chat_service = AzureChatCompletion(deployment_name=gpt_deployment_name, endpoint=endpoint, api_key=api_key)\n",
    "azure_text_embedding = AzureTextEmbedding(deployment_name=ada_deployment_name, endpoint=endpoint, api_key=api_key)\n",
    "kernel.add_chat_service(\"chat_completion\", azure_chat_service)\n",
    "kernel.add_text_embedding_generation_service(\"ada\", azure_text_embedding)\n",
    "\n",
    "mem_store = PostgresMemoryStore(conn_str,ADA_EMBEDDINGS_SIZE,1,3)\n",
    "kernel.register_memory_store(memory_store=mem_store)\n",
    "kernel.import_plugin(sk.core_plugins.TextMemoryPlugin(), \"text_memory\")\n",
    "print(\"Kernel is ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion\n",
    "\n",
    "### Read the files and chunk them by paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file: str)->str:\n",
    "    with open(file, \"r\") as f:\n",
    "        return f.read()\n",
    "    \n",
    "def ingest_content(path:str):\n",
    "    import os\n",
    "    chunks = []\n",
    "    files = os.listdir(path)\n",
    "    for f in files:\n",
    "        if f.endswith(\"water.txt\"):            \n",
    "            content = read_file(\"data/\"+f)\n",
    "            paragraphs = content.split(\"\\n\\n\")\n",
    "            l = len(paragraphs)\n",
    "            id = 1\n",
    "            for p in paragraphs:\n",
    "                lid = f\"{f}-{l}-{id}\"\n",
    "                c = {\"id\":lid,\"chunk\":p,\"file\":f}\n",
    "                chunks.append(c)\n",
    "                id += 1\n",
    "    return chunks\n",
    "\n",
    "chunks = ingest_content(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the chunks and embeddings in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def populate_memory(kernel: sk.Kernel, chunks: list) -> None:\n",
    "    for chunk in chunks:\n",
    "        await kernel.memory.save_information(collection=COLLECTION_NAME, id=chunk[\"id\"], text=chunk[\"chunk\"], description=chunk[\"file\"])\n",
    "\n",
    "await populate_memory(kernel, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grounding\n",
    "\n",
    "### Find memories based on query, and collect the text in the memories to augment the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_memory_examples(kernel: sk.Kernel, question: str, limit: int=3, relevance=0.75) -> list:\n",
    "    results = await kernel.memory.search(COLLECTION_NAME, question,limit,relevance)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Build a context from the text chunks in the memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the chemical composition of water?\"\n",
    "results = await search_memory_examples(kernel, question)\n",
    "prompt_context = \"Context: \\\"\\\"\\\"\\n\"\n",
    "\n",
    "for result in results:\n",
    "    prompt_context += f\"Text:\\n{result.text}\\nSource:\\n{result.description}\\n\"\n",
    "    \n",
    "prompt_context += \"\\\"\\\"\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Prompt & Completion\n",
    "\n",
    "### Create a SK function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTemplate = \"{{$input}}\\n\\nContext: ===\\n{{$context}}\\n===\\nAdd a source reference to the end of each sentence. e.g. Apple is a fruit [reference1.pdf][reference2.pdf]. Use only the provided text.\"\n",
    "rag_function = kernel.create_semantic_function(prompt_template=promptTemplate, max_tokens=500, temperature=0.3)\n",
    "\n",
    "skf_context = kernel.create_new_context()\n",
    "skf_context[\"input\"] = question\n",
    "skf_context[\"context\"] = prompt_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the Prompt and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:\n",
      "What is the chemical composition of water?\n",
      "\n",
      "assistant:\n",
      "Water is an inorganic compound with the chemical formula H2O. [wikipedia-water.txt]\n",
      "\n",
      "It is a transparent, tasteless, odorless, and nearly colorless chemical substance, and it is the main constituent of Earth's hydrosphere and the fluids of all known living organisms (in which it acts as a solvent). [wikipedia-water.txt]\n",
      "\n",
      "Water, a substance composed of the chemical elements hydrogen and oxygen and existing in gaseous, liquid, and solid states. [brittanica-water.txt]\n",
      "\n",
      "Although the molecules of water are simple in structure (H2O), the physical and chemical properties of the compound are extraordinarily complicated, and they are not typical of most substances found on Earth. [brittanica-water.txt]\n",
      "\n",
      "Its chemical formula, H2O, indicates that each of its molecules contains one oxygen and two hydrogen atoms, connected by covalent bonds. [wikipedia-water.txt]\n",
      "\n",
      "The hydrogen atoms are attached to the oxygen atom at an angle of 104.45Â°. [wikipedia-water.txt]\n",
      "\n",
      "Water also exists on other planets and moons both within and beyond the solar system. [brittanica-water.txt]\n",
      "\n",
      "In small quantities water appears colourless, but water actually has an intrinsic blue colour caused by slight absorption of light at red wavelengths. [brittanica-water.txt]\n",
      "\n",
      "For example, although the sight of ice cubes floating in a glass of ice water is commonplace, such behaviour is unusual for chemical entities. [brittanica-water.txt]\n",
      "\n",
      "For almost every other compound, the solid state is denser than the liquid state; thus, the solid would sink to the bottom of the liquid. [brittanica-water.txt]\n",
      "\n",
      "The fact that ice floats on water is exceedingly important in the natural world, because the ice that forms on ponds and lakes in cold areas of the world acts as an insulating barrier that protects the aquatic life below. [brittanica-water.txt]\n",
      "\n",
      "If ice were denser than liquid water, ice forming on a pond would sink, thereby exposing more water to the cold temperature. [brittanica-water.txt]\n",
      "\n",
      "Thus, the pond would eventually freeze throughout, killing all the life-forms present. [brittanica-water.txt]\n"
     ]
    }
   ],
   "source": [
    "result = await rag_function(context=skf_context)\n",
    "print(f\"user:\\n{question}\\n\\nassistant:\\n{result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v31012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
